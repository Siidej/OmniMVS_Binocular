# OmniMVS_Binocular
Based on papers: "[OmniMVS: End-to-End Learning for Omnidirectional Stereo Matching](https://openaccess.thecvf.com/content_ICCV_2019/papers/Won_OmniMVS_End-to-End_Learning_for_Omnidirectional_Stereo_Matching_ICCV_2019_paper.pdf)" and "[End-to-End Learning of Geometry and Context for Deep Stereo Regression](https://arxiv.org/pdf/1703.04309.pdf)"  
Modified for binocular system like Intel REALSENSE T265  
Codes were heavily borrowed from [matsuren/omnimvs_pytorch](https://github.com/matsuren/omnimvs_pytorch)  

## Detail
![image](https://github.com/Siidej/OmniMVS_Binocular/blob/master/images/tableau.png)  

## Dataset  
Dataset is generated by using [Habita-Sim](https://github.com/facebookresearch/habitat-sim) + [Replica-Dataset](https://github.com/facebookresearch/Replica-Dataset)  
![image](https://github.com/Siidej/OmniMVS_Binocular/blob/master/images/dataset.png)  

## Example  
![image](https://github.com/Siidej/OmniMVS_Binocular/blob/master/images/exemple.png)  


## Problem  
Because the realization of the double-sphere fisheye camera model in Habitat-Sim is a cubemap hacking ([check out here](https://github.com/facebookresearch/habitat-sim/issues/794)), the results are therefore not accurate. As we can see the cubemap's trace is remarkable:
![image](https://github.com/Siidej/OmniMVS_Binocular/blob/master/images/cubeMap.png)  
